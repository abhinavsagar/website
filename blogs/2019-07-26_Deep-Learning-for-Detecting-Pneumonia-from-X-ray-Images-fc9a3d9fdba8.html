<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Deep Learning for Detecting Pneumonia from X-ray Images</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Deep Learning for Detecting Pneumonia from X-ray Images</h1>
</header>
<section data-field="subtitle" class="p-summary">
Automatic pneumonia detection from X-ray images
</section>
<section data-field="body" class="e-content">
<section name="1307" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="75a0" id="75a0" class="graf graf--h3 graf--leading graf--title">Deep Learning for Detecting Pneumonia from X-ray Images</h3><h4 name="b6d2" id="b6d2" class="graf graf--h4 graf-after--h3 graf--subtitle">An end to end pipeline for pneumonia detection from X-ray images</h4><figure name="a298" id="a298" class="graf graf--figure graf-after--h4"><img class="graf-image" data-image-id="1*sE2lzbGqffqXZmHeooB0-g.jpeg" src="https://cdn-images-1.medium.com/max/800/1*sE2lzbGqffqXZmHeooB0-g.jpeg"></figure><p name="5a33" id="5a33" class="graf graf--p graf-after--figure">Stuck behind the paywall? Click <a href="https://medium.com/p/deep-learning-for-detecting-pneumonia-from-x-ray-images-fc9a3d9fdba8?source=email-c3f5233f3441--writer.postDistributed&amp;sk=fc89a046b5dcdda696aaeba7242b5e15" data-href="https://medium.com/p/deep-learning-for-detecting-pneumonia-from-x-ray-images-fc9a3d9fdba8?source=email-c3f5233f3441--writer.postDistributed&amp;sk=fc89a046b5dcdda696aaeba7242b5e15" class="markup--anchor markup--p-anchor" target="_blank">here</a> to read the full story with my Friend Link!</p><p name="593d" id="593d" class="graf graf--p graf-after--p">The risk of pneumonia is immense for many, especially in developing nations where billions face energy poverty and rely on polluting forms of energy. The WHO estimates that over 4 million premature deaths occur annually from household air pollution-related diseases including pneumonia. Over 150 million people get infected with pneumonia on an annual basis especially children under 5 years old. In such regions, the problem can be further aggravated due to the dearth of medical resources and personnel. For example, in Africa’s 57 nations, a gap of 2.3 million doctors and nurses exists. For these populations, accurate and fast diagnosis means everything. It can guarantee timely access to treatment and save much needed time and money for those already experiencing poverty.</p><p name="1cb1" id="1cb1" class="graf graf--p graf-after--p">This project is a part of the <a href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia" data-href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Chest X-Ray Images (Pneumonia)</a> held on Kaggle.</p><h3 name="03af" id="03af" class="graf graf--h3 graf-after--p">The Challenge</h3><p name="53d3" id="53d3" class="graf graf--p graf-after--h3">Build an algorithm to automatically identify whether a patient is suffering from pneumonia or not by looking at chest X-ray images. The algorithm had to be extremely accurate because lives of people is at stake.</p><figure name="aa68" id="aa68" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*J5wUMztRXZ_eHimMxULAnA.png" data-width="721" data-height="351" src="https://cdn-images-1.medium.com/max/800/1*J5wUMztRXZ_eHimMxULAnA.png"></figure><h3 name="9471" id="9471" class="graf graf--h3 graf-after--figure">Environment and tools</h3><ol class="postList"><li name="bbd0" id="bbd0" class="graf graf--li graf-after--h3"><a href="https://scikit-learn.org/stable/" data-href="https://scikit-learn.org/stable/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">scikit-learn</a></li><li name="0590" id="0590" class="graf graf--li graf-after--li"><a href="https://keras.io/" data-href="https://keras.io/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">keras</a></li><li name="f859" id="f859" class="graf graf--li graf-after--li"><a href="https://www.numpy.org/" data-href="https://www.numpy.org/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">numpy</a></li><li name="6b19" id="6b19" class="graf graf--li graf-after--li"><a href="https://pandas.pydata.org/" data-href="https://pandas.pydata.org/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">pandas</a></li><li name="b444" id="b444" class="graf graf--li graf-after--li"><a href="https://matplotlib.org/" data-href="https://matplotlib.org/" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">matplotlib</a></li></ol><h3 name="357e" id="357e" class="graf graf--h3 graf-after--li">Data</h3><p name="a7e4" id="a7e4" class="graf graf--p graf-after--h3">The dataset can be downloaded from the kaggle website which can be found <a href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia" data-href="https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>.</p><h3 name="0338" id="0338" class="graf graf--h3 graf-after--p">Where is the code?</h3><p name="0924" id="0924" class="graf graf--p graf-after--h3">Without much ado, let’s get started with the code. The complete project on github can be found <a href="https://github.com/abhinavsagar/Kaggle-tutorial" data-href="https://github.com/abhinavsagar/Kaggle-tutorial" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>.</p><p name="58d1" id="58d1" class="graf graf--p graf-after--p">Let’s start with loading all the libraries and dependencies.</p><figure name="43d0" id="43d0" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/fd2478671af5624c8f49290e9076ed32.js"></script></figure><p name="8a55" id="8a55" class="graf graf--p graf-after--figure">Next I displayed some normal and pneumonia images to just have a look at how much different they look from the naked eye. Well not much!</p><figure name="199c" id="199c" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/9ba045ee030f5e0c44085b5e0b865005.js"></script></figure><figure name="9d4d" id="9d4d" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*kn4y_p8HHGYmsrCVy10mFQ.png" data-width="1071" data-height="503" src="https://cdn-images-1.medium.com/max/800/1*kn4y_p8HHGYmsrCVy10mFQ.png"><figcaption class="imageCaption">Sample Images</figcaption></figure><p name="e783" id="e783" class="graf graf--p graf-after--figure">Then I split the data-set into three sets — train, validation and test sets.</p><figure name="8d21" id="8d21" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/e02b8f33bdbe5600c19d85dde41b5b6b.js"></script></figure><p name="bdc7" id="bdc7" class="graf graf--p graf-after--figure">Next I wrote a function in which I did some data augmentation, fed the training and test set images to the network. Also I created labels for the images.</p><p name="5d89" id="5d89" class="graf graf--p graf-after--p">The practice of data augmentation<strong class="markup--strong markup--p-strong"> </strong>is an effective way to increase the size of the training set. Augmenting the training examples allow the network to “see” more diversified, but still representative, data points during training.</p><p name="59a8" id="59a8" class="graf graf--p graf-after--p">Then I defined a couple of data generators: one for training data, and the other for validation data. A data generator<strong class="markup--strong markup--p-strong"> </strong>is capable of loading the required amount of data (a mini batch of images) directly from the source folder, convert them into <em class="markup--em markup--p-em">training data </em>(fed to the model) and <em class="markup--em markup--p-em">training targets </em>(a vector of attributes — the supervision signal).</p><blockquote name="e3f2" id="e3f2" class="graf graf--blockquote graf-after--p"><em class="markup--em markup--blockquote-em">For my experiments, I usually set the </em><code class="markup--code markup--blockquote-code"><em class="markup--em markup--blockquote-em">batch_size = 64</em></code><em class="markup--em markup--blockquote-em">. In general a value between 32 and 128 should work well. Usually you should increase/decrease the batch size according to computational resources and model’s performances.</em></blockquote><figure name="1610" id="1610" class="graf graf--figure graf--iframe graf-after--blockquote"><script src="https://gist.github.com/abhinavsagar/78bb6395464bde0663b804f94e4028b5.js"></script></figure><p name="6043" id="6043" class="graf graf--p graf-after--figure">After that I defined some constants for later usage.</p><figure name="9e41" id="9e41" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/188a38a5d10b988c25744ecce6893d4d.js"></script></figure><p name="22a4" id="22a4" class="graf graf--p graf-after--figure">The next step was to build the model. This can be described in the following 5 steps.</p><ol class="postList"><li name="25fb" id="25fb" class="graf graf--li graf-after--p">I used five convolutional blocks comprised of convolutional layer, max-pooling and batch-normalization.</li><li name="c57e" id="c57e" class="graf graf--li graf-after--li">On top of it I used a flatten layer and followed it by four fully connected layers.</li><li name="6f25" id="6f25" class="graf graf--li graf-after--li">Also in between I have used dropouts to reduce over-fitting.</li><li name="2275" id="2275" class="graf graf--li graf-after--li">Activation function was Relu throughout except for the last layer where it was Sigmoid as this is a binary classification problem.</li><li name="27e1" id="27e1" class="graf graf--li graf-after--li">I have used Adam as the optimizer and cross-entropy as the loss.</li></ol><p name="815f" id="815f" class="graf graf--p graf-after--li">Before training the model is useful to define one or more callbacks. Pretty handy one, are: <code class="markup--code markup--p-code">ModelCheckpoint</code> and <code class="markup--code markup--p-code">EarlyStopping</code>.</p><ul class="postList"><li name="bf81" id="bf81" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">ModelCheckpoint</strong>: when training requires a lot of time to achieve a good result, often many iterations are required. In this case, it is better to save a copy of the best performing model only when an epoch that improves the metrics ends.</li><li name="eafd" id="eafd" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">EarlyStopping</strong>: sometimes, during training we can notice that the generalization gap (i.e. the difference between training and validation error) starts to increase, instead of decreasing. This is a symptom of overfitting that can be solved in many ways (<em class="markup--em markup--li-em">reducing model capacity</em>, <em class="markup--em markup--li-em">increasing training data</em>, <em class="markup--em markup--li-em">data augumentation</em>, <em class="markup--em markup--li-em">regularization</em>, <em class="markup--em markup--li-em">dropout</em>, etc). Often a practical and efficient solution is to stop training when the generalization gap is getting worse.</li></ul><figure name="9991" id="9991" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*2zD7wwIwhIrHdr8F4urF2w.png" data-width="992" data-height="533" src="https://cdn-images-1.medium.com/max/800/1*2zD7wwIwhIrHdr8F4urF2w.png"><figcaption class="imageCaption">Early stopping</figcaption></figure><figure name="9a4d" id="9a4d" class="graf graf--figure graf--iframe graf-after--figure"><script src="https://gist.github.com/abhinavsagar/13f93b52f899a6a5d284cb4d9759e7be.js"></script></figure><p name="a314" id="a314" class="graf graf--p graf-after--figure">Next I trained the model for 10 epochs with a batch size of 32. Please note that usually a higher batch size gives better results but at the expense of higher computational burden. Some research also claim that there is an optimal batch size for best results which could be found by investing some time on hyper-parameter tuning.</p><figure name="d57c" id="d57c" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/1ca3d3a1b0756a6eeec9730e34869431.js"></script></figure><figure name="6c45" id="6c45" class="graf graf--figure graf--iframe graf-after--figure"><script src="https://gist.github.com/abhinavsagar/e8505f1a5146c71e132f10f777d5d9c9.js"></script></figure><p name="8ba1" id="8ba1" class="graf graf--p graf-after--figure">Let’s visualize the loss and accuracy plots.</p><figure name="49ea" id="49ea" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/65df0562ec447513dd4a7620ec850932.js"></script></figure><figure name="cd12" id="cd12" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*aNhCiZ5wrjKjqUG_JD6DwQ.png" data-width="612" data-height="224" src="https://cdn-images-1.medium.com/max/800/1*aNhCiZ5wrjKjqUG_JD6DwQ.png"><figcaption class="imageCaption"><strong class="markup--strong markup--figure-strong">Accuracy vs Epoch | Loss vs Epoch</strong></figcaption></figure><p name="bb04" id="bb04" class="graf graf--p graf-after--figure">So far so good. The model is converging which can be observed from the decrease in loss and validation loss with epochs. Also it is able to reach 90% validation accuracy in just 10 epochs.</p><p name="75a1" id="75a1" class="graf graf--p graf-after--p">Let’s plot the confusion matrix and get some of the other results also like precision, recall, F1 score and accuracy.</p><figure name="5431" id="5431" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/1eb48fe12e7524d423461a8c98b4c8df.js"></script></figure><pre name="e207" id="e207" class="graf graf--pre graf-after--figure">CONFUSION MATRIX ------------------<br>[[191  43]<br> [ 13 377]]<br><br>TEST METRICS ----------------------<br>Accuracy: 91.02564102564102%<br>Precision: 89.76190476190476%<br>Recall: 96.66666666666667%<br>F1-score: 93.08641975308642<br><br>TRAIN METRIC ----------------------<br>Train acc: 94.23</pre><p name="42b9" id="42b9" class="graf graf--p graf-after--pre">The model is able to achieve an accuracy of 91.02% which is quite good considering the size of data that is used.</p><h3 name="3faa" id="3faa" class="graf graf--h3 graf-after--p">Conclusions</h3><p name="6924" id="6924" class="graf graf--p graf-after--h3">Although this project is far from complete but it is remarkable to see the success of deep learning in such varied real world problems. I have demonstrated how to classify positive and negative pneumonia data from a collection of X-ray images. The model was made from scratch, which separates it from other methods that rely heavily on transfer learning approach. In the future this work could be extended to detect and classify X-ray images consisting of lung cancer and pneumonia. Distinguishing X-ray images that contain lung cancer and pneumonia has been a big issue in recent times, and our next approach should be to tackle this problem.</p><h3 name="a002" id="a002" class="graf graf--h3 graf-after--p">References/Further Readings</h3><div name="65c6" id="65c6" class="graf graf--mixtapeEmbed graf-after--h3"><a href="https://medium.com/datadriveninvestor/training-a-cnn-to-detect-pneumonia-c42a44101deb" data-href="https://medium.com/datadriveninvestor/training-a-cnn-to-detect-pneumonia-c42a44101deb" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/datadriveninvestor/training-a-cnn-to-detect-pneumonia-c42a44101deb"><strong class="markup--strong markup--mixtapeEmbed-strong">Training a CNN to detect Pneumonia</strong><br><em class="markup--em markup--mixtapeEmbed-em">I remember the day so well. My grandfather started getting random coughs and began having trouble breathing. He was…</em>medium.com</a><a href="https://medium.com/datadriveninvestor/training-a-cnn-to-detect-pneumonia-c42a44101deb" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="f4fa279f374ecdae901f2f06dce070c8" data-thumbnail-img-id="1*rZ8wn3AO4CtzW_DGSQJjPg.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*rZ8wn3AO4CtzW_DGSQJjPg.png);"></a></div><div name="1f38" id="1f38" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://becominghuman.ai/detecting-pneumonia-with-deep-learning-3cf49b640c14" data-href="https://becominghuman.ai/detecting-pneumonia-with-deep-learning-3cf49b640c14" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://becominghuman.ai/detecting-pneumonia-with-deep-learning-3cf49b640c14"><strong class="markup--strong markup--mixtapeEmbed-strong">Detecting Pneumonia with Deep Learning</strong><br><em class="markup--em markup--mixtapeEmbed-em">Pneumonia is lung inflammation caused by infection with virus, bacteria, fungi or other pathogens. According to…</em>becominghuman.ai</a><a href="https://becominghuman.ai/detecting-pneumonia-with-deep-learning-3cf49b640c14" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="564a01394a525d427a9a86bbd08e5716" data-thumbnail-img-id="1*kpnTxhCtAsMcMEacmkwkMQ.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*kpnTxhCtAsMcMEacmkwkMQ.jpeg);"></a></div><div name="900c" id="900c" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://stanfordmlgroup.github.io/projects/chexnet/" data-href="https://stanfordmlgroup.github.io/projects/chexnet/" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://stanfordmlgroup.github.io/projects/chexnet/"><strong class="markup--strong markup--mixtapeEmbed-strong">CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning</strong><br><em class="markup--em markup--mixtapeEmbed-em">The dataset, released by the NIH, contains 112,120 frontal-view X-ray images of 30,805 unique patients, annotated with…</em>stanfordmlgroup.github.io</a><a href="https://stanfordmlgroup.github.io/projects/chexnet/" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="0c8fee2b978cefe2fa4eef9bd386892f" data-thumbnail-img-id="0*rXWyhK-toBOBqvw0" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*rXWyhK-toBOBqvw0);"></a></div><h3 name="fa12" id="fa12" class="graf graf--h3 graf-after--mixtapeEmbed">Before You Go</h3><p name="5df9" id="5df9" class="graf graf--p graf-after--h3">The corresponding source code can be found here.</p><div name="c316" id="c316" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://github.com/abhinavsagar/Kaggle-tutorial" data-href="https://github.com/abhinavsagar/Kaggle-tutorial" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://github.com/abhinavsagar/Kaggle-tutorial"><strong class="markup--strong markup--mixtapeEmbed-strong">abhinavsagar/Kaggle-tutorial</strong><br><em class="markup--em markup--mixtapeEmbed-em">Sample notebooks for Kaggle competitions. Automatic segmentation of microscopy images is an important task in medical…</em>github.com</a><a href="https://github.com/abhinavsagar/Kaggle-tutorial" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="e2a191f1c7a2d883cee7f4b5846e46b7" data-thumbnail-img-id="0*RSEMkr4e70kWOxf7" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*RSEMkr4e70kWOxf7);"></a></div><p name="2843" id="2843" class="graf graf--p graf-after--mixtapeEmbed">Happy reading, happy learning and happy coding!</p><h3 name="33c7" id="33c7" class="graf graf--h3 graf-after--p">Contacts</h3><p name="924e" id="924e" class="graf graf--p graf-after--h3">If you want to keep updated with my latest articles and projects <a href="https://medium.com/@abhinav.sagar" data-href="https://medium.com/@abhinav.sagar" class="markup--anchor markup--p-anchor" target="_blank">follow me on Medium</a>. These are some of my contacts details:</p><ul class="postList"><li name="cb50" id="cb50" class="graf graf--li graf-after--p"><a href="https://abhinavsagar.github.io" data-href="https://abhinavsagar.github.io" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Personal Website</a></li><li name="575a" id="575a" class="graf graf--li graf-after--li"><a href="https://in.linkedin.com/in/abhinavsagar4" data-href="https://in.linkedin.com/in/abhinavsagar4" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Linkedin</a></li><li name="6139" id="6139" class="graf graf--li graf-after--li"><a href="https://medium.com/@abhinav.sagar" data-href="https://medium.com/@abhinav.sagar" class="markup--anchor markup--li-anchor" target="_blank">Medium Profile</a></li><li name="2e6d" id="2e6d" class="graf graf--li graf-after--li"><a href="https://github.com/abhinavsagar" data-href="https://github.com/abhinavsagar" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">GitHub</a></li><li name="de97" id="de97" class="graf graf--li graf-after--li graf--trailing"><a href="https://www.kaggle.com/abhinavsagar" data-href="https://www.kaggle.com/abhinavsagar" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Kaggle</a></li></ul></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@abhinav.sagar" class="p-author h-card">Abhinav Sagar</a> on <a href="https://medium.com/p/fc9a3d9fdba8"><time class="dt-published" datetime="2019-07-26T20:37:35.257Z">July 26, 2019</time></a>.</p><p><a href="https://medium.com/@abhinav.sagar/deep-learning-for-detecting-pneumonia-from-x-ray-images-fc9a3d9fdba8" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on April 28, 2021.</p></footer></article></body></html>