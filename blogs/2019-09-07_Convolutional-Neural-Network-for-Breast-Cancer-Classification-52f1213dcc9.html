<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Convolutional Neural Network for Breast Cancer Classification</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Convolutional Neural Network for Breast Cancer Classification</h1>
</header>
<section data-field="subtitle" class="p-summary">
Deep Learning for solving the most commonly diagnosed cancer in women
</section>
<section data-field="body" class="e-content">
<section name="2467" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="c18e" id="c18e" class="graf graf--h3 graf--leading graf--title">Convolutional Neural Network for Breast Cancer Classification</h3><h4 name="a104" id="a104" class="graf graf--h4 graf-after--h3 graf--subtitle">Deep Learning for solving the most commonly diagnosed <strong class="markup--strong markup--h4-strong">cancer</strong> in women</h4><figure name="a2b5" id="a2b5" class="graf graf--figure graf-after--h4"><img class="graf-image" data-image-id="1*1yVctUdL6Ekmeq-3OsojgQ.jpeg" data-width="6016" data-height="4000" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*1yVctUdL6Ekmeq-3OsojgQ.jpeg"><figcaption class="imageCaption">Photo by <a href="https://unsplash.com/@tamarabellis?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" data-href="https://unsplash.com/@tamarabellis?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Tamara Bellis</a> on <a href="https://unsplash.com/search/photos/pink-ribbon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" data-href="https://unsplash.com/search/photos/pink-ribbon?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Unsplash</a></figcaption></figure><p name="9dd0" id="9dd0" class="graf graf--p graf-after--figure">Stuck behind the paywall? Click <a href="https://medium.com/p/convolutional-neural-network-for-breast-cancer-classification-52f1213dcc9?source=email-c3f5233f3441--writer.postDistributed&amp;sk=cdc740178a784a00ec62a51aa87201b3" data-href="https://medium.com/p/convolutional-neural-network-for-breast-cancer-classification-52f1213dcc9?source=email-c3f5233f3441--writer.postDistributed&amp;sk=cdc740178a784a00ec62a51aa87201b3" class="markup--anchor markup--p-anchor" target="_blank">here</a> to read the full story with my Friend Link!</p><p name="6261" id="6261" class="graf graf--p graf-after--p">Breast cancer is the second most common cancer in women and men worldwide. In 2012, it represented about 12 percent of all new cancer cases and 25 percent of all cancers in women.</p><p name="092f" id="092f" class="graf graf--p graf-after--p">Breast cancer starts when cells in the breast begin to grow out of control. These cells usually form a tumor that can often be seen on an x-ray or felt as a lump. The tumor is malignant (cancer) if the cells can grow into (invade) surrounding tissues or spread (metastasize) to distant areas of the body.</p><h3 name="2398" id="2398" class="graf graf--h3 graf-after--p">The Challenge</h3><p name="bfe0" id="bfe0" class="graf graf--p graf-after--h3">Build an algorithm to automatically identify whether a patient is suffering from breast cancer or not by looking at biopsy images. The algorithm had to be extremely accurate because lives of people is at stake.</p><h3 name="97ae" id="97ae" class="graf graf--h3 graf-after--p">Data</h3><p name="3773" id="3773" class="graf graf--p graf-after--h3">The dataset can be downloaded from <a href="https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database-breakhis/" data-href="https://web.inf.ufpr.br/vri/databases/breast-cancer-histopathological-database-breakhis/" class="markup--anchor markup--p-anchor" rel="nofollow noopener noopener" target="_blank">here</a>. This is a binary classification problem. I split the data as shown-</p><pre name="7765" id="7765" class="graf graf--pre graf-after--p">dataset train<br>  benign<br>   b1.jpg<br>   b2.jpg<br>   //<br>  malignant<br>   m1.jpg<br>   m2.jpg<br>   //  validation<br>   benign<br>    b1.jpg<br>    b2.jpg<br>    //<br>   malignant<br>    m1.jpg<br>    m2.jpg<br>    //...</pre><p name="7a91" id="7a91" class="graf graf--p graf-after--pre">The training folder has 1000 images in each category while the validation folder has 250 images in each category.</p></div><div class="section-inner sectionLayout--outsetRow" data-paragraph-count="2"><figure name="9865" id="9865" class="graf graf--figure graf--layoutOutsetRow is-partialWidth graf-after--p" style="width: 50%;"><img class="graf-image" data-image-id="1*nA14PUxlIF7GTwIunZLo4A.png" data-width="700" data-height="460" src="https://cdn-images-1.medium.com/max/600/1*nA14PUxlIF7GTwIunZLo4A.png"></figure><figure name="d1cb" id="d1cb" class="graf graf--figure graf--layoutOutsetRowContinue is-partialWidth graf-after--figure" style="width: 50%;"><img class="graf-image" data-image-id="1*FyGSHuxJbaetPcEJOTTl8g.png" data-width="700" data-height="460" src="https://cdn-images-1.medium.com/max/600/1*FyGSHuxJbaetPcEJOTTl8g.png"><figcaption class="imageCaption" style="width: 200%; left: -100%;">Benign sample</figcaption></figure></div><div class="section-inner sectionLayout--outsetRow" data-paragraph-count="2"><figure name="28ff" id="28ff" class="graf graf--figure graf--layoutOutsetRow is-partialWidth graf-after--figure" style="width: 50%;"><img class="graf-image" data-image-id="1*JfgjfgoAWD6eoW79F7giDg.png" data-width="700" data-height="460" src="https://cdn-images-1.medium.com/max/600/1*JfgjfgoAWD6eoW79F7giDg.png"></figure><figure name="4d99" id="4d99" class="graf graf--figure graf--layoutOutsetRowContinue is-partialWidth graf-after--figure" style="width: 50%;"><img class="graf-image" data-image-id="1*ChAbsvIMrfk__LtpWxSyuQ.png" data-width="700" data-height="460" src="https://cdn-images-1.medium.com/max/600/1*ChAbsvIMrfk__LtpWxSyuQ.png"><figcaption class="imageCaption" style="width: 200%; left: -100%;">Malignant sample</figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><h3 name="a061" id="a061" class="graf graf--h3 graf-after--figure">CNN Architecture</h3><p name="42fb" id="42fb" class="graf graf--p graf-after--h3">Let’s go step by step and analyze each layer in the Convolutional Neural Network.</p><h4 name="1693" id="1693" class="graf graf--h4 graf-after--p">Input</h4><p name="49c1" id="49c1" class="graf graf--p graf-after--h4">A Matrix of pixel values in the shape of [WIDTH, HEIGHT, CHANNELS]. Let’s assume that our input is [32x32x3].</p><h4 name="6119" id="6119" class="graf graf--h4 graf-after--p"><strong class="markup--strong markup--h4-strong">Convolution</strong></h4><p name="c6fa" id="c6fa" class="graf graf--p graf-after--h4">The purpose of this layer is to receive a feature map. Usually, we start with low number of filters for low-level feature detection. The deeper we go into the CNN, the more filters we use to detect high-level features. Feature detection is based on ‘scanning’ the input with the filter of a given size and applying matrix computations in order to derive a feature map.</p><figure name="525b" id="525b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*yZQjaMKHjm1HzDF4t4juzg.png" data-width="1026" data-height="730" src="https://cdn-images-1.medium.com/max/800/1*yZQjaMKHjm1HzDF4t4juzg.png"><figcaption class="imageCaption">Convolution Operation</figcaption></figure><h4 name="8d3b" id="8d3b" class="graf graf--h4 graf-after--figure"><strong class="markup--strong markup--h4-strong">Pooling</strong></h4><p name="93bc" id="93bc" class="graf graf--p graf-after--h4">The goal of this layer is to provide spatial variance, which simply means that the system will be capable of recognizing an object even when its appearance varies in some way. Pooling layer will perform a downsampling operation along the spatial dimensions (width, height), resulting in output such as [16x16x12] for pooling_size=(2, 2).</p><figure name="4553" id="4553" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*fWOuJ-xjdIR2-7W63PnBtA.gif" data-width="312" data-height="174" src="https://cdn-images-1.medium.com/max/800/1*fWOuJ-xjdIR2-7W63PnBtA.gif"><figcaption class="imageCaption">Pooling Operation</figcaption></figure><h4 name="8fa0" id="8fa0" class="graf graf--h4 graf-after--figure"><strong class="markup--strong markup--h4-strong">Fully Connected</strong></h4><p name="ab7a" id="ab7a" class="graf graf--p graf-after--h4">In a fully connected layer, we flatten the output of the last convolution layer and connect every node of the current layer with the other nodes of the next layer. Neurons in a fully connected layer have full connections to all activations in the previous layer, as seen in regular Neural Networks and work in a similar way.</p><figure name="4809" id="4809" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*qsbsCVyu376kqdnNcdxmmw.png" data-width="948" data-height="230" src="https://cdn-images-1.medium.com/max/800/1*qsbsCVyu376kqdnNcdxmmw.png"><figcaption class="imageCaption">CNN Overview</figcaption></figure><h3 name="72f7" id="72f7" class="graf graf--h3 graf-after--figure">Image Classification</h3><p name="20a0" id="20a0" class="graf graf--p graf-after--h3">The complete image classification pipeline can be formalized as follows:</p><ul class="postList"><li name="cf93" id="cf93" class="graf graf--li graf-after--p">Our input is a training dataset that consists of <em class="markup--em markup--li-em">N</em> images, each labeled with one of 2 different classes.</li><li name="d204" id="d204" class="graf graf--li graf-after--li">Then, we use this training set to train a classifier to learn what every one of the classes looks like.</li><li name="f776" id="f776" class="graf graf--li graf-after--li">In the end, we evaluate the quality of the classifier by asking it to predict labels for a new set of images that it has never seen before. We will then compare the true labels of these images to the ones predicted by the classifier.</li></ul><h3 name="8692" id="8692" class="graf graf--h3 graf-after--li">Where is the code?</h3><p name="8b08" id="8b08" class="graf graf--p graf-after--h3">Without much ado, let’s get started with the code. The complete project on github can be found <a href="https://github.com/abhinavsagar/Breast-cancer-classification" data-href="https://github.com/abhinavsagar/Breast-cancer-classification" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>.</p><p name="c6f5" id="c6f5" class="graf graf--p graf-after--p">Let’s start with loading all the libraries and dependencies.</p><figure name="2ebb" id="2ebb" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/bfc7eb0c608c3ba0ba65f5dc365a0bce.js"></script></figure><p name="c847" id="c847" class="graf graf--p graf-after--figure">Next I loaded the images in the respective folders.</p><figure name="4357" id="4357" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/a2d8e96d41feddb51994793679c645f3.js"></script></figure><p name="25b4" id="25b4" class="graf graf--p graf-after--figure">After that I created a numpy array of zeroes for labeling benign images and similarly a numpy array of ones for labeling malignant images. I also shuffled the dataset and converted the labels into categorical format.</p><figure name="662c" id="662c" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/4000d397fa40a1ef93a0a7c5f9caa88c.js"></script></figure><p name="9a57" id="9a57" class="graf graf--p graf-after--figure">Then I split the data-set into two sets — train and test sets with 80% and 20% images respectively. Let’s see some sample benign and malignant images.</p><figure name="602d" id="602d" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/662d12f89919c514bac42e6e5811b4a3.js"></script></figure><figure name="dcfb" id="dcfb" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*xIb3HyemekonD8YQkf-pSQ.png" data-width="906" data-height="500" src="https://cdn-images-1.medium.com/max/800/1*xIb3HyemekonD8YQkf-pSQ.png"><figcaption class="imageCaption">Benign vs malignant samples</figcaption></figure><p name="73b5" id="73b5" class="graf graf--p graf-after--figure">I used a batch size value of 16. Batch size is one of the most important hyperparameters to tune in deep learning. I prefer to use a larger batch size to train my models as it allows computational speedups from the parallelism of GPUs. However, it is well known that too large of a batch size will lead to poor generalization. On the one extreme, using a batch equal to the entire dataset guarantees convergence to the global optima of the objective function. However this is at the cost of slower convergence to that optima. On the other hand, using smaller batch sizes have been shown to have faster convergence to good results. This is intuitively explained by the fact that smaller batch sizes allow the model to start learning before having to see all the data. The downside of using a smaller batch size is that the model is not guaranteed to converge to the global optima.Therefore it is often advised that one starts at a small batch size reaping the benefits of faster training dynamics and steadily grows the batch size through training.</p><p name="2321" id="2321" class="graf graf--p graf-after--p">I also did some data augmentation. The practice of data augmentation<strong class="markup--strong markup--p-strong"> </strong>is an effective way to increase the size of the training set. Augmenting the training examples allow the network to see more diversified, but still representative data points during training.</p><p name="618e" id="618e" class="graf graf--p graf-after--p">Then I created a data generator to get the data from our folders and into Keras in an automated way. Keras provides convenient python generator functions for this purpose.</p><figure name="2355" id="2355" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/d53fb34db685e4720a384bbd85821305.js"></script></figure><p name="7255" id="7255" class="graf graf--p graf-after--figure">The next step was to build the model. This can be described in the following 3 steps:</p><ol class="postList"><li name="c353" id="c353" class="graf graf--li graf-after--p">I used DenseNet201 as the pre trained weights which is already trained in the Imagenet competition. The learning rate was chosen to be 0.0001.</li><li name="2b27" id="2b27" class="graf graf--li graf-after--li">On top of it I used a globalaveragepooling layer followed by 50% dropouts to reduce over-fitting.</li><li name="26e3" id="26e3" class="graf graf--li graf-after--li">I used batch normalization and a dense layer with 2 neurons for 2 output classes ie benign and malignant with softmax as the activation function.</li><li name="d37a" id="d37a" class="graf graf--li graf-after--li">I have used Adam as the optimizer and binary-cross-entropy as the loss function.</li></ol><figure name="c988" id="c988" class="graf graf--figure graf--iframe graf-after--li"><script src="https://gist.github.com/abhinavsagar/4ad4469c3d9d235f77561ff55efb79c2.js"></script></figure><p name="a48c" id="a48c" class="graf graf--p graf-after--figure">Let’s see the output shape and the parameters involved in each layer.</p><figure name="38c3" id="38c3" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*6b5xmOLrFa2B7XXlGj9xPg.png" data-width="531" data-height="291" src="https://cdn-images-1.medium.com/max/800/1*6b5xmOLrFa2B7XXlGj9xPg.png"><figcaption class="imageCaption">Model summary</figcaption></figure><p name="e05e" id="e05e" class="graf graf--p graf-after--figure">Before training the model, it is useful to define one or more callbacks. Pretty handy one, are: ModelCheckpoint<strong class="markup--strong markup--p-strong"> </strong>and ReduceLROnPlateau.</p><ul class="postList"><li name="d77a" id="d77a" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">ModelCheckpoint</strong>: When training requires a lot of time to achieve a good result, often many iterations are required. In this case, it is better to save a copy of the best performing model only when an epoch that improves the metrics ends.</li><li name="543d" id="543d" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">ReduceLROnPlateau</strong>: Reduce learning rate when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2–10 once learning stagnates. This callback monitors a quantity and if no improvement is seen for a ‘patience’ number of epochs, the learning rate is reduced.</li></ul><figure name="4dfd" id="4dfd" class="graf graf--figure graf-after--li"><img class="graf-image" data-image-id="1*VAmbyfpR0_-gP0oIla0Vjw.png" data-width="947" data-height="487" src="https://cdn-images-1.medium.com/max/800/1*VAmbyfpR0_-gP0oIla0Vjw.png"><figcaption class="imageCaption">ReduceLROnPlateau.</figcaption></figure><p name="8619" id="8619" class="graf graf--p graf-after--figure">I trained the model for 20 epochs.</p><figure name="31be" id="31be" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/23471b3319664c527c0357fb10195e15.js"></script></figure><h3 name="78a5" id="78a5" class="graf graf--h3 graf-after--figure">Performance Metrics</h3><p name="38f5" id="38f5" class="graf graf--p graf-after--h3">The most common metric for evaluating model performance is the accurcacy. However, when only 2% of your dataset is of one class (malignant) and 98% some other class (benign), misclassification scores don’t really make sense. You can be 98% accurate and still catch none of the malignant cases which could make a terrible classifier.</p><figure name="8c0d" id="8c0d" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/814a4b1bcbe9d831f577288c52b1960d.js"></script></figure><figure name="2221" id="2221" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*ZQ7ssrY8HSG1PNaEKHty4A.png" data-width="375" data-height="252" src="https://cdn-images-1.medium.com/max/800/1*ZQ7ssrY8HSG1PNaEKHty4A.png"><figcaption class="imageCaption">Loss vs epoch</figcaption></figure><figure name="4f2a" id="4f2a" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*RNvuomRazqxobXBT5Wb5UA.png" data-width="381" data-height="252" src="https://cdn-images-1.medium.com/max/800/1*RNvuomRazqxobXBT5Wb5UA.png"><figcaption class="imageCaption">Accuracy vs epoch</figcaption></figure><h3 name="67cf" id="67cf" class="graf graf--h3 graf-after--figure">Precision, Recall and F1-Score</h3><p name="4319" id="4319" class="graf graf--p graf-after--h3">For a better look at misclassification, we often use the following metric to get a better idea of true positives (TP), true negatives (TN), false positive (FP) and false negative (FN).</p><p name="5452" id="5452" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Precision </strong>is the ratio of correctly predicted positive observations to the total predicted positive observations.</p><p name="de47" id="de47" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Recall </strong>is the ratio of correctly predicted positive observations to all the observations in actual class.</p><p name="8f43" id="8f43" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">F1-Score</strong> is the weighted average of Precision and Recall.</p><figure name="5d50" id="5d50" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="0*TKmn_WdhjibNGDcK" data-width="30" data-height="6" src="https://cdn-images-1.medium.com/max/800/0*TKmn_WdhjibNGDcK"></figure><figure name="152a" id="152a" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="0*vQRo8nPcqJhvc0Z-.png" data-width="375" data-height="84" src="https://cdn-images-1.medium.com/max/800/0*vQRo8nPcqJhvc0Z-.png"></figure><p name="dc38" id="dc38" class="graf graf--p graf-after--figure">The higher the F1-Score, the better the model. For all three metric, 0 is the worst while 1 is the best.</p><h3 name="d6fc" id="d6fc" class="graf graf--h3 graf-after--p">Confusion Matrix</h3><p name="402f" id="402f" class="graf graf--p graf-after--h3">Confusion Matrix is a very important metric when analyzing misclassification. Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class. The diagonals represent the classes that have been correctly classified. This helps as we not only know which classes are being misclassified but also what they are being misclassified as.</p><figure name="abdb" id="abdb" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/e9928e6eb7e0f322e40d4463e89a3782.js"></script></figure><figure name="a931" id="a931" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*KqNnbU_BudrZLVRc-w1gZg.png" data-width="322" data-height="280" src="https://cdn-images-1.medium.com/max/800/1*KqNnbU_BudrZLVRc-w1gZg.png"><figcaption class="imageCaption">Confusion matrix</figcaption></figure><h3 name="84a4" id="84a4" class="graf graf--h3 graf-after--figure">ROC Curves</h3><p name="9464" id="9464" class="graf graf--p graf-after--h3">The 45 degree line is the random line, where the Area Under the Curve or AUC is 0.5 . The further the curve from this line, the higher the AUC and better the model. The highest a model can get is an AUC of 1, where the curve forms a right angled triangle. The ROC curve can also help debug a model. For example, if the bottom left corner of the curve is closer to the random line, it implies that the model is misclassifying at Y=0. Whereas, if it is random on the top right, it implies the errors are occurring at Y=1.</p><figure name="6d1f" id="6d1f" class="graf graf--figure graf--iframe graf-after--p"><script src="https://gist.github.com/abhinavsagar/77eb498e67fadda8beb6434b842b797e.js"></script></figure><figure name="5f66" id="5f66" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*DA5k2v5qczkJY0Ykt7PSBQ.png" data-width="389" data-height="278" src="https://cdn-images-1.medium.com/max/800/1*DA5k2v5qczkJY0Ykt7PSBQ.png"><figcaption class="imageCaption">ROC-AUC curve</figcaption></figure><h3 name="e51d" id="e51d" class="graf graf--h3 graf-after--figure">Results</h3><figure name="a183" id="a183" class="graf graf--figure graf-after--h3"><img class="graf-image" data-image-id="1*NxsCFwa-whil_CgZgxVC1g.png" data-width="575" data-height="69" src="https://cdn-images-1.medium.com/max/800/1*NxsCFwa-whil_CgZgxVC1g.png"><figcaption class="imageCaption">Final results</figcaption></figure><h3 name="1a97" id="1a97" class="graf graf--h3 graf-after--figure">Conclusions</h3><p name="6253" id="6253" class="graf graf--p graf-after--h3">Although this project is far from complete but it is remarkable to see the success of deep learning in such varied real world problems. In this blog, I have demonstrated how to classify benign and malignant breast cancer from a collection of microscopic images using convolutional neural networks and transfer learning.</p><h3 name="88d2" id="88d2" class="graf graf--h3 graf-after--p">References/Further Readings</h3><div name="b46e" id="b46e" class="graf graf--mixtapeEmbed graf-after--h3"><a href="https://towardsdatascience.com/transfer-learning-for-image-classification-in-keras-5585d3ddf54e" data-href="https://towardsdatascience.com/transfer-learning-for-image-classification-in-keras-5585d3ddf54e" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://towardsdatascience.com/transfer-learning-for-image-classification-in-keras-5585d3ddf54e"><strong class="markup--strong markup--mixtapeEmbed-strong">Transfer Learning for Image Classification in Keras</strong><br><em class="markup--em markup--mixtapeEmbed-em">One stop guide to Transfer Learning</em>towardsdatascience.com</a><a href="https://towardsdatascience.com/transfer-learning-for-image-classification-in-keras-5585d3ddf54e" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="85c469422b9cefc676813c630cb6e3e4" data-thumbnail-img-id="1*IQ3Vt2eP3B9ubvwkPGVAvw.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*IQ3Vt2eP3B9ubvwkPGVAvw.jpeg);"></a></div><div name="2535" id="2535" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://towardsdatascience.com/predicting-invasive-ductal-carcinoma-using-convolutional-neural-network-cnn-in-keras-debb429de9a6" data-href="https://towardsdatascience.com/predicting-invasive-ductal-carcinoma-using-convolutional-neural-network-cnn-in-keras-debb429de9a6" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://towardsdatascience.com/predicting-invasive-ductal-carcinoma-using-convolutional-neural-network-cnn-in-keras-debb429de9a6"><strong class="markup--strong markup--mixtapeEmbed-strong">Predicting Invasive Ductal Carcinoma using Convolutional Neural Network (CNN) in Keras</strong><br><em class="markup--em markup--mixtapeEmbed-em">Classifying histopathology slides as malignant or benign using Convolutional Neural Network</em>towardsdatascience.com</a><a href="https://towardsdatascience.com/predicting-invasive-ductal-carcinoma-using-convolutional-neural-network-cnn-in-keras-debb429de9a6" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="7bc2b72806ddf658c3551ecd88506a0d" data-thumbnail-img-id="1*dD7oWfCLnS8kHPZLqHo5yg.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*dD7oWfCLnS8kHPZLqHo5yg.png);"></a></div><div name="0339" id="0339" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0214587" data-href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0214587" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0214587"><strong class="markup--strong markup--mixtapeEmbed-strong">Breast cancer histopathological image classification using convolutional neural networks with small…</strong><br><em class="markup--em markup--mixtapeEmbed-em">Although successful detection of malignant tumors from histopathological images largely depends on the long-term…</em>journals.plos.org</a><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0214587" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="5659db5c26afa47a14252203967d0747" data-thumbnail-img-id="0*HErxPH_I_pLYzzrs" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*HErxPH_I_pLYzzrs);"></a></div><div name="e379" id="e379" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://becominghuman.ai/deep-learning-for-image-classification-with-less-data-90e5df0a7b8e" data-href="https://becominghuman.ai/deep-learning-for-image-classification-with-less-data-90e5df0a7b8e" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://becominghuman.ai/deep-learning-for-image-classification-with-less-data-90e5df0a7b8e"><strong class="markup--strong markup--mixtapeEmbed-strong">Deep Learning for Image Classification with Less Data</strong><br><em class="markup--em markup--mixtapeEmbed-em">Deep Learning is indeed possible with less data</em>becominghuman.ai</a><a href="https://becominghuman.ai/deep-learning-for-image-classification-with-less-data-90e5df0a7b8e" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="b2946d2a3953dd81426e343a220e61ee" data-thumbnail-img-id="1*7zKjE0bIN7pzZaU_y5558Q.jpeg" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*7zKjE0bIN7pzZaU_y5558Q.jpeg);"></a></div><h3 name="a39b" id="a39b" class="graf graf--h3 graf-after--mixtapeEmbed">Before You Go</h3><p name="1abc" id="1abc" class="graf graf--p graf-after--h3">The corresponding source code can be found here.</p><div name="1b6c" id="1b6c" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://github.com/abhinavsagar/Breast-cancer-classification" data-href="https://github.com/abhinavsagar/Breast-cancer-classification" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://github.com/abhinavsagar/Breast-cancer-classification"><strong class="markup--strong markup--mixtapeEmbed-strong">abhinavsagar/Breast-cancer-classification</strong><br><em class="markup--em markup--mixtapeEmbed-em">Benign vs Malignant classifier using convolutional neural networks The dataset can be downloaded from here. pip install…</em>github.com</a><a href="https://github.com/abhinavsagar/Breast-cancer-classification" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="7f17f6c48cd8e1720b60b187c7fa7caa" data-thumbnail-img-id="0*f6q_pJGfRJ69tuNj" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*f6q_pJGfRJ69tuNj);"></a></div><h3 name="ccb1" id="ccb1" class="graf graf--h3 graf-after--mixtapeEmbed">Contacts</h3><p name="924e" id="924e" class="graf graf--p graf-after--h3">If you want to keep updated with my latest articles and projects <a href="https://medium.com/@abhinav.sagar" data-href="https://medium.com/@abhinav.sagar" class="markup--anchor markup--p-anchor" target="_blank">follow me on Medium</a>. These are some of my contacts details:</p><ul class="postList"><li name="25c0" id="25c0" class="graf graf--li graf-after--p"><a href="https://abhinavsagar.github.io" data-href="https://abhinavsagar.github.io" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Personal Website</a></li><li name="575a" id="575a" class="graf graf--li graf-after--li"><a href="https://in.linkedin.com/in/abhinavsagar4" data-href="https://in.linkedin.com/in/abhinavsagar4" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Linkedin</a></li><li name="6139" id="6139" class="graf graf--li graf-after--li"><a href="https://medium.com/@abhinav.sagar" data-href="https://medium.com/@abhinav.sagar" class="markup--anchor markup--li-anchor" target="_blank">Medium Profile</a></li><li name="2e6d" id="2e6d" class="graf graf--li graf-after--li"><a href="https://github.com/abhinavsagar" data-href="https://github.com/abhinavsagar" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">GitHub</a></li><li name="de97" id="de97" class="graf graf--li graf-after--li"><a href="https://www.kaggle.com/abhinavsagar" data-href="https://www.kaggle.com/abhinavsagar" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">Kaggle</a></li></ul><p name="a64c" id="a64c" class="graf graf--p graf-after--li graf--trailing">Happy reading, happy learning and happy coding!</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@abhinav.sagar" class="p-author h-card">Abhinav Sagar</a> on <a href="https://medium.com/p/52f1213dcc9"><time class="dt-published" datetime="2019-09-07T15:08:15.857Z">September 7, 2019</time></a>.</p><p><a href="https://medium.com/@abhinav.sagar/convolutional-neural-network-for-breast-cancer-classification-52f1213dcc9" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on April 28, 2021.</p></footer></article></body></html>