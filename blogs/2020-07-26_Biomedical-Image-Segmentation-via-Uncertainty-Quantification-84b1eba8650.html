<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Biomedical Image Segmentation via Uncertainty Quantification</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Biomedical Image Segmentation via Uncertainty Quantification</h1>
</header>
<section data-field="subtitle" class="p-summary">
Enhancing interpretability using bayesian neural networks
</section>
<section data-field="body" class="e-content">
<section name="5e75" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="b136" id="b136" class="graf graf--h3 graf--leading graf--title">Biomedical Image Segmentation via Uncertainty Quantification</h3><h4 name="888c" id="888c" class="graf graf--h4 graf-after--h3 graf--subtitle">Enhancing interpretability using bayesian neural networks</h4></div><div class="section-inner sectionLayout--fullWidth"><figure name="7d36" id="7d36" class="graf graf--figure graf--layoutFillWidth graf-after--h4"><img class="graf-image" data-image-id="1*ujV51hLZDDvCz2GcfoNfYA.jpeg" data-width="5880" data-height="3850" data-is-featured="true" src="https://cdn-images-1.medium.com/max/2560/1*ujV51hLZDDvCz2GcfoNfYA.jpeg"><figcaption class="imageCaption">Photo by <a href="https://unsplash.com/@davidclode?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" data-href="https://unsplash.com/@davidclode?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">David Clode</a> on <a href="https://unsplash.com/s/photos/brain?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" data-href="https://unsplash.com/s/photos/brain?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" class="markup--anchor markup--figure-anchor" rel="noopener" target="_blank">Unsplash</a></figcaption></figure></div><div class="section-inner sectionLayout--insetColumn"><p name="746f" id="746f" class="graf graf--p graf-after--figure">In the past decade, deep learning has been highly successful in a range of applications. However for validation and interpretability, not only do we need the predictions made by the model but also how confident it is while making those predictions. This is very important in medical imaging for the clinicians to accept it. In this blog, we present our research carried out at Vellore Institute of Technology. We used an encoder decoder architecture based on variational inference techniques for segmenting brain tumour images. We compared different backbones architectures like U-Net, V-Net and FCN as sampling data from the conditional distribution for the encoder. We evaluate our work on the publicly available BRATS dataset using Dice Similarity Coefficient (DSC) and Intersection Over Union (IOU) as the evaluation metrics.</p><h3 name="f84f" id="f84f" class="graf graf--h3 graf-after--p">Medical Image Segmentation</h3><p name="cfb6" id="cfb6" class="graf graf--p graf-after--h3">The problem of segmenting medical images have been successfully tackled in literature using mainly two techniques, first using a Fully Convolutional Network (FCN) and second those which are based on U-Net. The main characteristic of FCN architectures is that it doesn’t use fully connected layers at the end which have been used successfully for image classification problems. U-Net, on the other hand, uses an encoder-decoder architecture with pooling layers in the encoder and upsampling layers in the decoder.</p><h3 name="8e02" id="8e02" class="graf graf--h3 graf-after--p">Bayesian Neural Network</h3><p name="cd18" id="cd18" class="graf graf--p graf-after--h3">It is a scalable approach of avoiding overfitting in neural networks and at the same time gives us a measure of uncertainty. Instead of point estimates, the neural network learns posterior distribution over the weights given the dataset as given in the equation below.</p><figure name="5a96" id="5a96" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*LoAxlfi-kV7SOW7BM-yqcQ.png" data-width="616" data-height="109" src="https://cdn-images-1.medium.com/max/800/1*LoAxlfi-kV7SOW7BM-yqcQ.png"></figure><p name="08e2" id="08e2" class="graf graf--p graf-after--figure">The predictive distribution can be calculated by approximating the integral as shown in the equation below.</p><figure name="dce2" id="dce2" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*6z9oPTm4d5X1W5jHosu_0A.png" data-width="527" data-height="111" src="https://cdn-images-1.medium.com/max/800/1*6z9oPTm4d5X1W5jHosu_0A.png"></figure><h3 name="2ce1" id="2ce1" class="graf graf--h3 graf-after--figure">Variational Inference</h3><p name="a9c9" id="a9c9" class="graf graf--p graf-after--h3">Variational inference finds the parameters of the distribution by maximizing the Evidence Lower Bound. ELBO consists of sum of two terms Kullback-Leibler (KL) divergence between prior and posterior distributions and the negative log-likelihood (NLL). The KL divergence term which needs to be minimized is shown in the equation below.</p><figure name="f78c" id="f78c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*gF6qHsJ09melC9y3ha6qAg.png" data-width="357" data-height="81" src="https://cdn-images-1.medium.com/max/800/1*gF6qHsJ09melC9y3ha6qAg.png"></figure><p name="bb8b" id="bb8b" class="graf graf--p graf-after--figure">The KL divergence is defined as shown in the equation below.</p><figure name="f9ab" id="f9ab" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*SuzhUKUOBx6a42PILIp0sA.png" data-width="499" data-height="105" src="https://cdn-images-1.medium.com/max/800/1*SuzhUKUOBx6a42PILIp0sA.png"></figure><p name="dc0e" id="dc0e" class="graf graf--p graf-after--figure">Since the integral in the equation above is intractable in nature, it can be written in an alternative form. The equation can be converted to an optimization problem as shown in the equation below.</p><figure name="816b" id="816b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*KYk85_Uhpl-kmYOPTuabCg.png" data-width="881" data-height="209" src="https://cdn-images-1.medium.com/max/800/1*KYk85_Uhpl-kmYOPTuabCg.png"></figure><h3 name="98d5" id="98d5" class="graf graf--h3 graf-after--figure">Aleatoric Uncertainty and Epistemic Uncertainty</h3><p name="ccb5" id="ccb5" class="graf graf--p graf-after--h3">There are two types of uncertainty — aleatory and epistemic uncertainty where variance is the sum of both these. For final predictions, single mean and variance can be estimated as shown in the two equations below.</p><figure name="0f22" id="0f22" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*akqaFCzbAj93VJoDYxXzBg.png" data-width="331" data-height="110" src="https://cdn-images-1.medium.com/max/800/1*akqaFCzbAj93VJoDYxXzBg.png"></figure><figure name="34a9" id="34a9" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*bP5gam46ciV8m1jVPZCyOQ.png" data-width="592" data-height="124" src="https://cdn-images-1.medium.com/max/800/1*bP5gam46ciV8m1jVPZCyOQ.png"></figure><p name="f40c" id="f40c" class="graf graf--p graf-after--figure">The first term in variance denotes aleatoric uncertainty while the second denotes epistemic uncertainty</p><h3 name="f6ab" id="f6ab" class="graf graf--h3 graf-after--p">Network Architecture</h3><p name="bd7d" id="bd7d" class="graf graf--p graf-after--h3">The prior distribution helps to incorporate learning of the weights over the network. Our model uses a similar encoder decoder architecture as that used in VAEs with the input to the encoder coming from a pre trained image segmentation architecture. The input to the encoder only needs the mean the standard deviation vectors of the conditional distribution expressing the confidence with which the pixels are correctly predicted. After passing through the encoder, the parameters get converted to a latent representation which is again sampled in a mean and standard deviation vector. The decoder later recovers this back to the original distribution. The conventional backpropagation algorithm is used for training the model with gradient descent. The model architecture used in this work is shown in Figure 1:</p><figure name="5f01" id="5f01" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*7YsznN6aDIKy51oOSDPxPg.png" data-width="704" data-height="305" src="https://cdn-images-1.medium.com/max/800/1*7YsznN6aDIKy51oOSDPxPg.png"><figcaption class="imageCaption">Figure 1: Our model architecture</figcaption></figure><h3 name="8fd9" id="8fd9" class="graf graf--h3 graf-after--figure">Algorithm</h3><p name="f0fe" id="f0fe" class="graf graf--p graf-after--h3">The algorithm used for training the network is shown below which is based on Stochastic Gradient Descent.</p><figure name="7509" id="7509" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Rur2iSSl8Q8Ct4SlT5PaWg.png" data-width="1097" data-height="525" src="https://cdn-images-1.medium.com/max/800/1*Rur2iSSl8Q8Ct4SlT5PaWg.png"></figure><h3 name="cdd5" id="cdd5" class="graf graf--h3 graf-after--figure">Datasets</h3><p name="ba98" id="ba98" class="graf graf--p graf-after--h3">To evaluate the performance of our network, BRATS18 brain tumour segmentation dataset was used. It contains MRI scans of 175 patients with glioblastoma and lower grade glioblastoma. The images were of resolution 240×240×155 pixels. The ground truth labels were created by expert neuroradiologists. A sample from the dataset is shown in Fig 2.</p><figure name="54c4" id="54c4" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*d-pzjY6aGO5nItQrBOBdkw.png" data-width="425" data-height="330" src="https://cdn-images-1.medium.com/max/800/1*d-pzjY6aGO5nItQrBOBdkw.png"><figcaption class="imageCaption">Figure 2: Example of MRI slices and ground truth segmentation</figcaption></figure><h3 name="032f" id="032f" class="graf graf--h3 graf-after--figure">Evaluation Metrics</h3><p name="681a" id="681a" class="graf graf--p graf-after--h3">Evaluation metrics used in this work are Dice Similarity Coefficient (DSC) also known as F1-score and Intersection over union (IoU). The corresponding equations are shown below.</p><figure name="b6ad" id="b6ad" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*FVUJfk9pkI1lqvIX5q084Q.png" data-width="397" data-height="116" src="https://cdn-images-1.medium.com/max/800/1*FVUJfk9pkI1lqvIX5q084Q.png"></figure><figure name="258b" id="258b" class="graf graf--figure graf-after--figure"><img class="graf-image" data-image-id="1*NtNMQZccVx6pMy7VUQQYSQ.png" data-width="339" data-height="105" src="https://cdn-images-1.medium.com/max/800/1*NtNMQZccVx6pMy7VUQQYSQ.png"></figure><h3 name="d3e5" id="d3e5" class="graf graf--h3 graf-after--figure">Loss Functions</h3><p name="8c40" id="8c40" class="graf graf--p graf-after--h3">A combination of binary cross entropy and dice losses have been used to train the network. The first part binary cross entropy is a commonly used loss function for classification problems as shown in equation below:</p><figure name="cbc8" id="cbc8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*upwwfxaB5RSkN2VgBQ2zwQ.png" data-width="608" data-height="97" src="https://cdn-images-1.medium.com/max/800/1*upwwfxaB5RSkN2VgBQ2zwQ.png"></figure><p name="32b7" id="32b7" class="graf graf--p graf-after--figure">The problem with binary cross entropy loss is that it doesn’t take into account the class imbalance as the background is the dominant class. Dice Loss handles this problem which can be written as shown in the below equation.</p><figure name="442e" id="442e" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*pwvPtB01yddT7ZHa-pNrgA.png" data-width="694" data-height="104" src="https://cdn-images-1.medium.com/max/800/1*pwvPtB01yddT7ZHa-pNrgA.png"></figure><p name="fea5" id="fea5" class="graf graf--p graf-after--figure">Both the loss terms were combined in a single term with more weight given to the Dice Loss term since it handles the class imbalance problem better. This is defined using the equation below.</p><figure name="f5a8" id="f5a8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*DJ4AGK3sqw-ZhC5PgpiBnQ.png" data-width="410" data-height="70" src="https://cdn-images-1.medium.com/max/800/1*DJ4AGK3sqw-ZhC5PgpiBnQ.png"></figure><h3 name="b330" id="b330" class="graf graf--h3 graf-after--figure">Results</h3><p name="2b46" id="2b46" class="graf graf--p graf-after--h3">The uncertainty involved in segmentation is shown in Fig 3. The darker color denotes more confidence while the lighter means the model is less confident in those areas.</p><figure name="da4c" id="da4c" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*FVmEalRPKgVcRvtIyg7idw.png" data-width="916" data-height="348" src="https://cdn-images-1.medium.com/max/800/1*FVmEalRPKgVcRvtIyg7idw.png"><figcaption class="imageCaption">Figure 3: Examples of models predictions on test samples, compared to ground truth segmentation. First column: input image, second column: ground truth segmentation, third column: predicted segmentation, fourth column: aleatoric uncertainty and fifth column: epistemic uncertainty</figcaption></figure><h3 name="c967" id="c967" class="graf graf--h3 graf-after--figure">Conclusions</h3><p name="e050" id="e050" class="graf graf--p graf-after--h3">In this blog, we presented a way to quantify uncertainty in the context of medical image segmentation. Our model is based on an encoder decoder framework similar to that used by VAEs. The weights of the network represent distributions instead of point estimates and thus give a principled way of measuring uncertainty at the same time while making the predictions. The inputs to encoder come from pre trained backbones architectures like U-Net, V-Net, FCN sampled from conditional distribution representing the confidence with which pixels are labelled correctly. We evaluate our results on publicly available BRATS dataset with our network outperforming previous state of the art results using DSC and IOU metrics.</p><h3 name="c17c" id="c17c" class="graf graf--h3 graf-after--p">References</h3><p name="5371" id="5371" class="graf graf--p graf-after--h3">M. S. Ayhan and P. Berens. Test-time data augmentation for estimation of heteroscedastic aleatoric uncertainty in deep neural networks. 2018.</p><p name="192f" id="192f" class="graf graf--p graf-after--p">Y. Gal. Uncertainty in deep learning. University of Cambridge, 1(3), 2016.</p><p name="3e29" id="3e29" class="graf graf--p graf-after--p">Y. Gal and Z. Ghahramani. Bayesian convolutional neural networks with bernoulli approximate variational inference. arXiv preprint arXiv:1506.02158, 2015.</p><p name="22eb" id="22eb" class="graf graf--p graf-after--p">D. P. Kingma and M. Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013. D. P. Kingma, T. Salimans, and M. Welling.</p><p name="8bc6" id="8bc6" class="graf graf--p graf-after--p">Variational dropout and the local reparameterization trick. In Advances in neural information processing systems, pages 2575–2583, 2015.</p><h3 name="ef47" id="ef47" class="graf graf--h3 graf-after--p">Before You Go</h3><p name="990c" id="990c" class="graf graf--p graf-after--h3">Paper:<strong class="markup--strong markup--p-strong"> </strong><a href="https://arxiv.org/pdf/2008.07588" data-href="https://arxiv.org/pdf/2008.07588" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://arxiv.org/pdf/2008.07588</a></p><p name="4061" id="4061" class="graf graf--p graf-after--p graf--trailing">Code:<strong class="markup--strong markup--p-strong"> </strong><a href="https://github.com/abhinavsagar/uqvi" data-href="https://github.com/abhinavsagar/uqvi" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">https://github.com/abhinavsagar/uqvi</a></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@abhinav.sagar" class="p-author h-card">Abhinav Sagar</a> on <a href="https://medium.com/p/84b1eba8650"><time class="dt-published" datetime="2020-07-26T19:00:48.812Z">July 26, 2020</time></a>.</p><p><a href="https://medium.com/@abhinav.sagar/biomedical-image-segmentation-via-uncertainty-quantification-84b1eba8650" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on April 28, 2021.</p></footer></article></body></html>